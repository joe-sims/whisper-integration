Meeting Summary: Gitlab-AI-Simon
Generated: 2025-08-05 06:57:34
Audio File: audio_input/Gitlab-AI-Simon.m4a
Model: Claude (claude-sonnet-4-20250514)

--------------------------------------------------
SUMMARY
--------------------------------------------------

# Meeting Overview
- **Date:** Not specified
- **Attendees:** Simon (GitLab AI Champion & UK SA Leader), Joe, Andrea, Roberto, Daniela
- **Meeting Type:** Customer Meeting / Knowledge Sharing Session

## Executive Summary
GitLab's AI Champion shared comprehensive insights on implementing AI tools across go-to-market operations, demonstrating automated workflows that save days of manual work for BDRs/SDRs. The session covered practical implementations from basic Claude prompts to sophisticated automation workflows, with Entrust exploring similar AI adoption initiatives under new CEO leadership.

## Key Discussion Points
- **Account Research Automation:** GitLab automated BDR account research using Claude with web search, reducing days of manual work to 5-minute automated processes | Impact: Massive time savings, higher quality outreach
- **Workflow Automation Platform:** Using Make.com and N8N to create end-to-end automated workflows for account research, strategic planning, and customer success plan updates | Impact: Consistent, accurate, always-updated customer information
- **AI Agent Implementation:** Technical Q&A agent in Slack answering 90% of technical questions within 5 minutes using internal knowledge base | Impact: Faster problem resolution, reduced dependency on tribal knowledge

## Decisions & Approvals
- **Decision:** Entrust to explore similar AI implementation as strategic company-wide initiative | Impact: Go-to-market transformation | Approver: New incoming CEO

## Action Items
- [ ] **Explore N8N for workflow automation** - Owner: Entrust team | Due: Not specified | Priority: High
- [ ] **Review Anthropic prompt engineering course** - Owner: Entrust team | Due: Not specified | Priority: Medium
- [ ] **Assess API access requirements for automation** - Owner: Entrust team | Due: Not specified | Priority: High

## Team & Performance Updates
- **Team member updates:** GitLab seeing 100% adoption of automated account research across BDR/SDR teams
- **Pipeline/Forecast changes:** Higher response rates and click rates from more tailored, AI-generated outreach
- **Customer escalations:** None mentioned

## Risks & Dependencies
- **Risk:** Model accuracy degradation with chained AI processes | Impact: Delivery quality | Mitigation: Use workflow automation with selective AI integration rather than full agent chains
- **Risk:** Lack of dedicated resources for implementation | Impact: Team adoption | Mitigation: Assign dedicated person/team for AI workflow development

## Follow-up Required
- **Before next engagement:** Entrust to evaluate current AI tooling and identify priority use cases
- **Cross-functional:** Engage with new CEO on strategic AI initiative
- **Escalations:** None required

## Key Metrics Mentioned
- **Resource/Capacity:** Account research reduced from days to 5 minutes per account
- **Customer satisfaction:** 90% of technical questions answered within 5 minutes via AI agent
- **Revenue/Pipeline:** Improved response rates and click rates from personalized outreach

---
*Focus on practical implementation guidance and change management for AI adoption in go-to-market operations.*

--------------------------------------------------
FULL TRANSCRIPT  
--------------------------------------------------

 new CEOs, new CROs, there's a fair bit going on at the moment. So yeah, I've seen it all really. And I've led the SA team, which is our essays, across Amir for a couple of years, and then I've kind of built the team around me now. So actually, I really look after UK now. It's really very simple. I just make my job less and less important, as I hire new people. Yeah. And so that's really where I am. But I guess the bit that's kind of maybe more relevant to this conversation is, I'm also one of the AI champions at GitLab. So what does that mean? It means that I am the AI champion for the whole of the go-to market organisation. So when you're talking about internal use cases for AI, I'm the person who's really kind of spearheading, like kind of what we should be doing and how we should be thinking, and looking for new and interesting use cases. So that's kind of probably a little bit of the background of that. Anyone? Yeah, thanks Simon. Yeah, just to give you context. Like I shared with this team kind of some of the things you've shown me about what you do at GitLab. Like I haven't gone into much detail, but I wanted to last-wide people like Andrea was interested to see what you guys at GitLab do. Yeah, and Simon just as a context. First of all, thanks a lot for taking the time, because it really appreciate the brainstorming, showing the experience and so on that you're doing there. We are driving an initiative also inside of Entrust, or better Entrust ID verification, which is really the core amphito company, of innovating our kind of sales talk. Of course, we use AI as a core of our product. Our product is fundamentally AI, what we do, identity verification and so on. But if I got to be honest, that inside our sales team and inside of the company, we are still on the early adopter phase. Yeah, I do. So there's a few experiments that we're running out. We'll actually have some also like bigger investment as an Entrust company on AI tools and AI processes. So really, when Joe mentioned, hey, there's something cool there. We should ask them if they do us the courtesy of talking about that. I was really excited about it. So again, just to say, thank you very much for sharing your learnings and very much looking forward to it. And I understand that we use a lot of the same terminologies, the command of the message and stuff like that. So it's a really good. Yeah, so Gidgetlab is a command of the message, MedPick, that is our sales methodology there. So yeah, I've seen that you're also quite open as a company. You have a big public handbook. A lot of public playbook and so on. So that's really, it's really nice and a great to see a company operating like that. So I just want to make that part of the context. Yeah, no problem at all. I mean, let me sort of what I do is I'll walk you through the journey of kind of like how we've approached AI and kind of where we've got to now. There's some things I can't share, obviously, but I will share some of the journeys to where we've got to now. And it will hopefully give you something to think about. If you get bored or you want me to move on, then just just interrupt me. Like I'm not precious, right? But I have got a few things to share. So I will start at the beginning. So actually before I start, which of you, I'm assuming you have access to an AI model of some sort, whether that's Claude or chat to you, or even like, you know, O'Lama or something like that locally. Copilot is kind of the one that we're kind of allowed to use within interest, because we're a Microsoft house. So do you have API access? One of the things I was going to ask you, API access to open AI's API, or is it purely just like the chat interface really? Just a chat in the face. Okay, so let's start that, right? Okay, so, but that will change. So one of the things that we just moved my window across, so I can see you all still two seconds. So one of the things that we started off is in a very similar situation to you. We have access to Claude. Claude is our model provider of choice at the moment, what anthropic is. And just like we just said, then it's the chat box, right? So you type stuff and you get responses. So one of the use cases that we identified in the go-to market organization that was like taking loads of time at the moment in terms of building pipeline, especially with the BDRs and the SDRs, was like, look, say you get given your set of accounts. Let's just pick a random account. Let's say you get done album or someone like that, like a high street bank or something like that. How do you approach that customer? It is really important because you actually only get one chance at first introduction, right? You can send one first email ever, right? And after that, everything is built upon that foundation. So BDRs naturally get told that they need to research as much as they possibly can. It takes them days, weeks, sometimes longer, right? And so one of the things that we found that was really a really great use case for AI always straight out the box was to use Claude Web Search and deep research to do an initial account research. So we created this as a GitLab issue, if you haven't seen GitLab before. Sorry, this is a GitLab issue. This is where we document pretty much everything. And so like we kind of created this, which sort of goes through like setting up Claude account and basically turning on extended thinking and turning on Web Search. This is a slightly older model now. It's been around for a little while. But the idea being like we're just kind of giving people the idea like look, we want to use the biggest model with with reasoning mode turned on and ideally deep research, which is the take your time mode. And then what we what we ended up doing was like providing a prompt. People generally in my experience aren't great at doing prompt engineering. There is a great course by Anthropic that's pretty much usable to any model. So if you're interested type in Anthropic prompt engineering course and it will come up, I'll find you later if you're interested. But it tells you how to do really good prompts. And so what we did is we kind of just created this pre prompt. Here it says I'm a go to market team member at GitLab conducting research on blank. As a potential or an existing account, please provide a comprehensive analysis. And what we are interested in is digital transformation strategy, software development practices, recent acquisitions, earnings reports, tooling that they use, DevOps and security posture, cloud infrastructure, technology pain points, key technologies, competitive landscape, DevSecOps initiatives and potential buying decision criteria. You'd be amazed how public some companies are about these kinds of things in their earnings reports or in sometimes they do, if some of the really big companies out there do like DevOps reports internally to show kind of what their strategy is and their vision is. So, I'm sorry, Andrea, yeah, go for it. Yeah, just sorry, I know if we make it interactive, like, of course. So, cloud does actually out of their training web research for all of these stuff. So what it does is it does both. So if you turn on the options we've got here, effectively it has the ability to browse the internet. It also has the ability to look at all of the training data that it's got as part of the model. So it uses both. And it uses its reasoning mode to try and figure out where it would be the best place to go and get my information. So it conducts research in a whole host of different places, is the reality. And some of the results it comes back with are pretty mind blowing really in terms of how good they are. You obviously have to check it for validity. These models can hallucinate, but they tend not to when you give them very strong prompts like this. And on that, sorry, just to add on that and that they also, I think, close the circular return the sources. So you will see when you do research mode, you have like 40 footnote. And those are all the sources. So you can actually have a look and say actually that source maybe was a blogger complaining about that and not really. Yeah, the regional source. Yeah, so I mean, like, I mean, if you want, I'm literally copy and paste this into hold on. I mean, it's great in your chat now. I can literally do it now. So I can do, let's do opus. Let's do, let's do web. Let's do extended thinking and let's do research. And oh, yeah, unfortunately, when you copy and paste it from here, you have to put it into a, actually, it's going to be a bit of a pain. But in short, really, let me just see if I can copy it like text. The problem is when it goes past a certain length, Claude likes to put it in in a paste, which then means so what you actually have to do is copy and paste it into a CF3 file. And then edit the company name and then repaste it back in. So I can't show you live, but that's kind of how the how that would work. And the results it comes back with is phenomenal. It creates a full report. We asked for it in Mark down format. The reason why that is as you can paste it straight into a Google Doc and then it's all formatted with correctly with headings and links and citations and everything. And we would give that to the BDR and say, look, hey, you've just been given this account. Here's a load of account research, right? So this is just one use case that we kind of we kind of came up with and then we kind of take it one step further, which is that once you've got all that account research. And you can actually start playing around with some of the artifacts that we have. So there's another issue here, which is like how to use Claude practice basically for street presets account planning and engagement. So we've got about 13 use cases now documented so everything from like command plan generation. I don't know if you use command plans and assuming you might know. So command of the message is basically command plan. So like why now what value driver what's the solution? What's the capability? Why get lab? Why do anything at all? Very command of the message kind of. And when you when you look at here, the this is really interesting because I was having a conversation with outreach the other day about it. Did you train Claude with your own value framework? You don't have to. So I'll show you at the top of the top on this and so these are all the use cases we've identified, but all of this basically revolves around building a project. So what we do is we actually include you create a project. So over here you've got projects. I'm probably going to show you a company name, but yeah, like so for example, like that one there. And you can put in some contextual information. So what we do is as it says here, it tells you to what to do. You create a project and you basically give it a load of project knowledge. Now we've got generic content and if you click on that, I'm not sure if I've actually logged in at the moment. And not okay. But basically in that folder, we've got like a list of command of the message, handbook pages. So you just said that we have public handbook is very open. Well, actually our public handbook has all of the command of the message framework in it and med pick analysis in it and how we work. So that page I've taken as a mark down file and put it into that Google Drive folder. I've got our value drivers and our value framework in a PDF and that's in that folder. And the nice thing about that is then I add all of that into the project context. So every single question you then ask the Claude. LLM in that project context, it's effectively using it as a rag of retrieval augmented generation. So it has access to all the value drivers has access to all of that command of the message framework. You can see here you can see like command on message and med pick content style guide that's like how GitLab communicates. So we want to make sure that anything it produces is in our kind of voice and how we like to communicate with customers. The value framework we've got like things like the forest, a total economic impact report specifically created for GitLab, the global demo setups report, these kinds of things. They're generic. So they get lab specific, but that just adds to the ability for Claude to answer things in a GitLab way. Yeah, yeah, absolutely. Yeah, because my view is kind of using these as you say to kind of supercharged sales enable rate as well. And those things get refreshed every now and then. So my main point the other day with outreach, they were saying, oh, you build these cards. And like, well, if you need to build content cards every time, you kind of duplicate work every time and you end up with stale, stale information, all the product that we launch are not there. So one of the nice things about Claude is it does integrate with Google Docs and Google Docs. If you update the original Google Doc, you don't have to read at it. It just refreshes it every single time you go in. So if like some of your content is in Google slides, Google Docs, Google Sheets, that content auto update, include, I'm sure there's similar stuff in the co-pilot as well. But the key bit here is at the top like this was GitLab specific content, but we also add things like this. So like ongoing meeting notes, Docs. So that's in Google Docs. So we have so for an account. So let's just do done out again as a high street name. If we haven't done on ongoing notes, Doc, we would add that as well. So not only then does it have access to our command of the message and our medbic. It's now access to everything we've discussed with that customer. If you use things like Gong or any kind of cool recording software, you can also ingest those transcripts and so on, which then means it's even more knowledgeable. And that is why you can then do things like use case one, which is like based on our account documentation. So based on everything you know about this customer, help me generate the opportunity overview section addressing these things. Now, if the problem is with LLMs, if you ask them to do something, they will do it. So even if there's hardly any account documentation, it will still answer these questions. So the way that we solve that is there is a project instruction sector, which is basically like a pre a pre prompt. And it says down here, if you recall any information, more information to any prompt given don't hesitate to ask questions as well as providing context as to why they needed. It also says, please be radically candid when answering the team is trying to get insights as well as areas of strength and weakness. If you feel like there is an area where we're lacking call it out, this is really important and a pre prompt because otherwise you've asked it a question and it will give you an answer regardless of whether it actually knows the answer or not. By kind of pre prompting in that way, it means that you are more likely to get an answer like, sorry, I can't do that, Dave. That kind of thing. So like why now we don't have enough information to understand the why now like that is something you need to go and find and it will give us that information back rather than just going, oh, probably because they're x, y, z. So yeah, but there's some command plan generation, account plan generation meeting planning follow up, so setting agenda for the next meetings, once you've got all that information in a project, you can interact with it and say like, look, based on the most recent discussion we had. And the follow up actions we've done x, y, z, what do you think the agenda should be for the next meeting and it will give you some ideas and give you some prompting there. You can do strategic email outreach. So if you don't, if you haven't actually spoken to a customer yet, the way that we do this is is pretty, pretty intense, but here we go. So based on our account research and account plan, please create a strategic email drafts and what we ask it is for is for 12 different emails, which is basically three different senders for different recipients. So we say like, look, send, create an email for an account executive to send to a CCO, CIO, CISO, head of DevOps, technical individual, then create one from a BDR, create one from an essay. And so what it tends to do is like the essay emails will be quite a lot more technical and like hey, like kind of leaning on a hey, I'm a technical expert, I'm your, you know, that kind of persona, where is the BDR one will be like more slightly more marketing and the account executive one will be like, hi, I don't know if you're aware of this behind your account executive. And so it crafts all those emails for you in that would like 12 tailored emails at the end, which is, which is lovely. Again, good prompting like keep emails between a certain length, make sure it's aligned with that command of the message, failing work and valley drivers. So again, about the prompt. But all of this stuff that I've shown you so far really requires you to copy and paste into Claude. So that is kind of where you're at. And so you end up with things like this, and we, we've got things like the GitLab Solutions Architect Assistant, which is kind of cool. So this is a generic one. This isn't specific for an account. But you can see we've got like command of the message. We've got account planning schema information. So like the kind of format that we expect an account plan to be in. We've got a GitLab technical evaluation guide. We've got content style guides, 10 reasons for GitLab with a GitLab. Forrest the economic impact report, the entirety of the essay public handbook, and then the job family, which is kind of like what our roles and responsibilities are. And so, and you can see there's a pre prompt as well, which is like you are expert solutions architect. You have years of experience of working your core characteristics. So these you have expertise in this you, you know, when responding to queries, you should be trying to understand the context and requirements. And what that leads to is some really interesting questions. So for example, I did one the other day, where one of my essays was saying like this is what I've been given by the BDR. Sorry to dunk on sales now, but is this acceptable in terms of like this is everything I've been given from the BDR. Is this is this set up for success and it was like I need to be radically candid with you. This is absolutely not an acceptable sale to process and you're right to be frustrated like zero proper discovery, no understanding of business drivers, no qualification. But then not only does it do that, it also says like look for tomorrow's call you need to reset things right tomorrow. We need to like spend the first 20 minutes doing some discovery. Ask some of these questions. Do it short for demo and then focus only on the relevant capabilities and then continue with discovery like longer term we need to actually fix this. But so you can get some really interesting kind of playbooks stuff out of it. It can help with enablement as well. So like I've been using the essay assistant to say like I'm trying to create some enablement for the essays. Like I want to feed back on it so it creates like how we you know might structure some enablement and like what what the plan should be and you just kind of back and forth like it's an iterative approach. Never does it ever get it right first time, but I think this is really really powerful when you use them in this way. And this is a shared project that like this is a shared project that everyone and the team can access so that everyone has access to get lab solutions architect assistant. Yeah, that project is going to but it's still copy and paste. But it's got a lot of the pre pro is all other kind of pre pre set up is done before people so they can just interact with it and it makes it easier. No, sorry technicality. All the project knowledge. Can you lock it to avoid everyone using this assistant and my mistake just drop a new file or a more file. The answer is yes, but coming soon anthropic actually so when you share it you add it and you you can you can currently have can edit or remove access to everyones an admin. So there is just a kind of a working policy at where we have like just no one touches this other than basically who maintains it but anthropic are busy working on like kind of having a role below administrators so that you can access the project and use it and interact with it. It can't change any of the pre pre pre prompt or any other content source but yeah. The other option is you can just duplicate it as well. So if you you can share it and just duplicate it and share that with someone if you want to kind of have a but the problem is then you start diverging if the content gets updated. So everything I've shown you so far is kind of like copy and paste you get answers out you still need to pull them out and then I think the thing that's kind of maybe more interesting is where we're kind of going next with that. So there's a couple of applications we're using to automate some of this stuff. So if I go into this is a product called make make.com it's an automation engine. So you saw earlier that there was that prompt to try and get as much company research as possible and about an account that requires copying and pasting that prompting and filling in the account name part of the reason why it didn't work is because frankly we don't use it very much anymore because we have this. And so what this is like a Google sheet it connects with our Google environment and have Google sheet an account exactly comes in and puts an account name into that Google sheet and that triggers this workflow and then what it does is it goes and spins out a load of different things so what it goes and does is goes and ask anthropic Claude and if you look in here you can see. Hey look this is a very familiar prompt. This is the one you saw earlier but this time it's got the account name and that account name has come from the Excel file. So it knows what the account name is and it's going to it's saying the same thing says exactly the same as what you saw earlier. It's set up to use certain version of Claude and it then passes that into mark down. Converts the mark down and HTML trucks it into a Google doc updates the Google sheet so now all of a sudden you've got the account name and you've got an account research documents out next to it. After it's got that account research it then feeds that account research into another prompt which says here is the value framework so we talked to earlier about the GitLab value framework but then it goes and feeds in the account research and says this is everything we know about the customer. This is how we sell how do you recommend we actually go and strategically plan to go and get into this account again that generates a document mark down sorry mark down into HTML document put back in this Google sheet. You've got all of the account research and you've got a strategic plan for how to go and get into that account down here it does a couple more so that we've got similar prompts for find find decision makers and influencers so do your account research to really dive deep into who in the business is likely to be involved in the decision making process. And down here we've got one for job posting so it actually goes and looks at job postings and finds you know kind of try to understand a bit more about the text acting goes really deep into that aspect of it like what jobs are they hiring for. Do they have any of our competitors listed or anything that's weird we might be able to kind of attach to again that just creates Google docs and puts them into a Google sheet nice thing then is at the end of this running which takes about five minutes probably. The account exact that has all of those documents available to them in a single Google sheet. I guess you were in the SAT and this is process your one of the concept was what's the kind of uptake you've seen for everyone everyone is using it like I mean the whole of it so I mean to the point where not even. Just new accounts are being utilized this way so existing accounts are also being utilized this way people actually still want to know more about so we've got another flow as well which also looks for news from the last 30 days and basically every two weeks kind of posts an update to a slack channel and goes like look this customer's been in the news in the last 30 days for these things. And if something major happens it will actually announce it to the channel so like if someone's have like a day to breach or something like that all the time and hacked you know we kind of get instant notifications for that as well. From a more slightly more CS sorry sorry essay or SE perspective we also have customer success plans what we're asked to be generate as part of our pre sales engagement and then we kind of hand them off to the CS team to then kind of take and run. They follow a very specific format and actually that's kind of quite critical to this working if they don't follow a specific format it's kind of impossible to do we use gone for our call recording so. Updating CSPs at the moment is really really arduous in terms of the essay spend a lot of time updating CSPs or customer success plans after I would say after every call but the reality is they don't because it's just so arduous that they don't do after every call. Which leads to CSPs that are always slightly out of date and maybe are updated so long after the fact that there's like interpretation of what was said rather than the reality of what was said. The nice thing about gone recordings is we have a recording in a transcript in a summary of what was said so every single time a gone recording is published we fire this workflow. That then goes and looks for the ongoing meeting notes doc so the gone recording is what was said on the call the ongoing meeting notes is what the team manually captured on that call. And what we do is we basically collate both of those two sources of information we get the current customer success plan from GitLab it is stored in a yaml file at the moment but could be anywhere right and we feed that into a Claude and say look based on the most recent call here's the gone call. The most recent notes here's the most recent notes and the current customer success plan if one exists at all what updates would you recommend that we make to that customer success plan and then what it goes and does is it makes those updates creates a merger quest in GitLab. Pings the USA on Slack and says hey you just had a call with this customer what I heard was this this and this I've updated the CSP in this way going review it and if you like it just merge it if you don't like it modify it if you don't like it at all kill the merger request. And saving hours hours of time right yeah and the absolutely and the merger quest here because just for context the most because you use GitLab also as your CRM right so. So yeah so we use GitLab for when we dog food GitLab for pretty much everything so all of our. That plans are held in GitLab is sort of source code so yeah you could use any platform frankly you could use it yeah yeah yeah yeah for us potentially in the what we're looking at is potentially to digest all of that within sales for. Yeah you can you can integrate with this for Salesforce as well just as easily so you can do Salesforce Salesforce and you can also like triggers as well so like for example when a record changes or a certain field on a record changes you can trigger a work fly you can create a really insert the lead to jobs make API calls you can you can pretty much do whatever you want in Salesforce based on these kinds of things so that's just kind of another idea of the kinds of things that we're doing which is a slide and some of this make dot com is a tool that is for doing workflow automation of this kind right so if you've heard of like Zapier back in the days or Zapier back in the day or like if this then that then they're kind of like the precursors to make and then workato make dot com N8N and actually it looks like we're kind of using make and N8N at the moment I'll show you N8N in a second but they all do the same thing right like the nice thing about N8N is it has a free tier free tier and you can self manage so actually can do a lot for free with N8N which is probably love as the barrier to entry let's just say and if it's self managed then it also reduces the security risk that makes a cloud based service and is paid for you basically pay per not per execution but you just pay per compute basically minutes minutes spent computing and then just kind of highlight one of the other use cases so this is N8N this is this is an N8N instance very similar kind of look as you can see like it's not that not that similar from what you just saw is this slightly different workflow so this runs on a schedule so every single day goes and gets a file from GitHub but anyway in they in GitHub there is a publicly community collaborated version of a document that can be used in the community and it's not a distributed version of a document that collates all of the different AI news feeds so RSS feeds they're basically every single source of AI news so what I'm doing here is I'm getting that extracting all the RSS feeds from that going and reading all the RSS feeds then I'm eliminating anything that wasn't published yesterday so I only want yesterday's content I aggregate that back I put into an AI agent so this is an agent now so I've got an anthropic as a model but it's not just an anthropic as a model so I'm going to get that as I'm talking about it but I've also got memory and I've got the ability to give access to tooling and what I'm saying here is like, you are an AI assistant tasked with creating a daily new summary of email. Here's the most recent news content. Your goal is to do X, Y, Z, prioritize this. Make sure you include links and resources, keep the email to a certain length. And then it goes away and basically turns it to mark down HTML sends a message on Gmail and what you end up with is something that looks like this. And this happens every single day. So every single day I get an update in terms of what's going on in the world of AI. Sometimes it's things that are really relevant. Sometimes it's things that are slightly more just kind of like what hold my beer kind of moment really. But this is a great example of like, and the nice thing about having memory is in the news, obviously lots of things are reported multiple times of the course of days and like sometimes some of the faster news sites get it day one and then slower news sites get it. The fact it's got memory over the last 14 days means it doesn't repeat itself. It only repeats itself if there's been a meaningful change in the actual news that's being reported on something. So these are the kind of things. Is this meeting just being a pretty loose to get enough to sign up to your newsletter? Yeah, you can sign up to the news letter if you want. But yeah, it's not my news letter. It's an AI news letter. I'm just a distributor. Oh yeah. That's really cool. Daniela. Good question. And have you been trying to measure the success of this approach or for example, rate of meeting books by the SDRs? Are all SDRs adopting this process or is just a fraction of voluntary? I'm assuming you're not running a test. Or have you seen like, get from the first of January adopt that this is suddenly meeting books rate was 20% higher? So et cetera. So how are you trying to measure this? So there's a few things that we can measure. So in the workflow automation tools, one of the things you can do, which is quite cool, is you can actually assign a number of minutes that would normally have been, it would normally have taken someone to do it. And the nice thing that means then, you get for every single execution of a automated workflow, you actually get a number at the end in terms of time saved. So it calculates how long it did take to run the automation. And you tell it how long it would have taken a human being to do that. So you can actually get some big numbers. And they are huge numbers. I mean, just to be clear, the account research one is saving days, days a week for a BDR, right? Multiple days a week. Because a lot of what their time is spent doing is looking for who they should contact, how they should contact, what's relevant to that business. And I think, yeah, we've seen huge amounts more emails coming out at the BDR team. And we've seen it a lot more outreach, right? And not only that, but that outreach is far more tailored and far more specific to the individual that we're actually sending it to than we've ever been able to send it before, which means our response rates are going up, click rates are going up. When it comes to CSPs, we're just seeing CSPs being more evergreen in terms of those customer success plans quite often kind of got left for a month before being updated. Whereas now we're kind of seeing them that they're always up to date. They're always got the latest information. And the nice thing about AI is that AI doesn't have happy years. Sales people have happy years. I say sometimes have happy years. AI does not. So it's more likely to actually tell you exactly what happened in a meeting and what the customer said rather than what an essay or an account executive interpreted the customer saying. So we're also leading into more app. We think it's more accurate information as well. Cool. I don't know if there's anything else that you wanted to see. Work question. How long did it take to build this process up? And also how many people were involved beside yourself? So to build the workflows, it depends on where you're coming into it. If you already have a clear idea, it is to what you're trying to achieve. I can give you an example of another one actually. While we're talking through this. So for example, the essays came and said, we're really struggling to find technical answers to questions sometimes. Customers come up to us with really technical questions. But they're too specific to be in the documentation. So it's like, I've installed GitLab on AWS in EC2. And I have this firewall and I'm using this load balancer and it's giving me this error. How do I solve that? Now I'll give you that support question, but that's the kind of thing. We're not going to put that exact scenario in. Good to hear. Good to hear that it's a similar pain across different businesses, Joe Robby. It's here. Let's see. I think you don't have web views. I was going to say that. But the interesting thing with that statement is that it's far too specific to put in documentation. So you're not going to find that answer in documentation, but generally someone else, so you're relying on tribal knowledge. You're relying on someone else having it encountered that problem before. And so what the essays have, we actually have a stack overflow, an internal stack overflow, where we have Q&A kind of things for more specific problems that we wouldn't put in documentation. And so what we did is we have a Slack channel where people ask these questions that sometimes people don't respond. A lot of the time, people don't respond. Sometimes they don't respond because they haven't seen it. Sometimes they respond because they just don't know the answer. And the problem is there's an essay who's asked the question, it's really frustrating because no one's responding to my question. It's like, why is everyone ignoring me? And it's not what they're ignoring you. It's that they don't know the answer, right? And so what we did is we used make to create an agent. Actually, it's the wrong one. Here we have this one, sorry. And so what what mate does is it monitors a Slack channel. So we have a CS questions or an essay questions channel. And every single time a question is posted in there, not in a thread, but is a top level question. It triggers this workflow. And then what it does is it runs an agent. And this is a slightly different thing from everything else I've shown you. So this isn't really kind of done here. This is actually done in a different bit, but know that it triggers an agent and I'll go to the agent now. Get a technical helper. And so this is the agent. So it's got a prompt much like you've seen everywhere else, but it's not a prompt for it doing a specific thing. It's kind of telling you, you are this. This is what you're trying to focus on doing like accurate responses. And this is what I want you to do. Like analyze the question, research, computer, comprehensively formulate responses, provide actionable guidance and validate the alignment. But this is where it starts to get a little bit more powerful because it's got things like MCP service support. So you can add in specific context like MedPick, command of the message, say for example, which doesn't change when there's a fixed thing. But you can add in MCP service support. So like for example, we can say, go and look at our stack overflow. And what it has access to the ability to do is go, hey, someone's asked a question about EC2 with this load balancer. Is there anything in stack overflow? And it will get that information back to it to help it formulate a response. You can also give it access to tooling, which actually then means it allows to go and do things for people. So this is where it gets really powerful. So this action down here, for example, is we could have done this with MCP, but it was another example. Like take the account name. So this scenario busy inputs and outputs. It takes in an account name. It goes to Google Drive and it searches for that account name in Google Drive. And then it just returns all of the content that's got on that account name. And what that means is that then that AI agent that has everything it needs to know about that account. Right? And so you can train it as well. So you can do like kind of fine tuning on it as well. And what this means is that NSA now posts a question. And the very first thing that will come back with then about five minutes roughly is an AI answer saying, this is what you're asking. This is how I understand it. This is what I think is the answer. These are why I think it's the answer. These are the sources I would recommend you go and check. And 90% of the questions in CS questions are now answered within five minutes. And if we can like take advantage of your experience and rolling it out. What if we start on these, not if, given that we are starting these route of also us as a company adopting these tools. What would be your main suggestion as things to watch out for? Like, I will careful of these. I got burned here. And if I had to do it again, I wouldn't do this way, but that way. I would say probably the most important thing is not to run before you can walk. So the agents are great. Everyone's talking about agents, agent everything. And you'll see loads of like tools are putting agents into everything. And they can do all of these things for you, right? But actually, I still think that there is a place for workflow automation tools with kind of if this, then that logic. And the reason why I would say that is because agents basically involve AI every step in the process. And the problem with that is that AI might be really good at giving you a 90% accurate answer. But if it's 90% accurate and you involve it 12 times, then it's compounding errors, right? So what you end up with is as it goes through that step more and more and more, you actually get much less of a reliable result. Building workflow automation tools, where you've got if this, then that. And then you can only use the AI when you really need to use the AI. That means you maintain that 90% accuracy. So that would be one thing I would say is don't add like AI, AI, and jadezichain AI, because what you'll tend to find is that the result at the end is 40% accurate or 50% accurate. So I do think there's a place for workflow automation tools even in this world of agents and agents being able to do everything for you. The reality is that we know our process better than an agent does. And so actually building that process and then only using AI where it's actually required and the process is often going to give you more accurate results. Okay. And I guess you tried a lot of different tools and ways you showed us a couple of those. But if you take a step back and look at the holistic go-to market, what are the main ones that you feel really made a difference for you? I mean, for the team. I think the workflow automation tools are up there. So like NAN make whichever tool, frankly, ZPIA, workato, all do the same thing. Make an end and a slightly more user friendly and slightly easier to use. Makes the probably the easiest to use. But to revert to, I realized I didn't answer your question. How many people? One, how long did it take? If I knew the workflow an hour? Maybe two? Yeah, no, that is the really good together. And I understand this like creating a project and then trying to find a way to do it. If you know what you're doing, it's quick, but it was more like from a company perspective, right, to bring people on that journey, to basically shift from the BDR thinking, oh, I know how to do customer research. So let me do it, to start using this tool that maybe is new. And I mean, if I need to explain someone how to do it. People would take much longer. Yeah. I think it starts with leadership. I think the only thing I would say is that everyone's always really worried that their job is going to be automated away. And I think you have to freight, you have to go in with that mentality in terms of like, we are not trying to automate your jobs away. What we are trying to do is take the bits of your job that you hate because it's the really tedious time-consuming bit that you have to do over and over and over again. And we're trying to make that easier, right? Like we pay BDRs because they know how to do good outreach. We don't really pay BDRs to do account research, right? That's just a prerequisite for doing good outreach. You want to do really good outreach. You need to know who the customer is. You need to know who the person is your messaging. Let's take that bit away from your job and let you focus on how do we use that information in the best possible way, right? That's what we pay them for. Same goes for essays like, we don't pay essays to build customer success plans. We build essays because they're technical experts. We want them to be trusted advisors. We want them to focus on building relationships with the customer and selling, frankly. And solving customer pain points. We don't want them spending four days understanding why this load balancer plus this EC2 instance plus this configuration of GitLab causes this error. Not interesting, right? It's about framing. No, because the... For me, I guess we're next for you now. Like, you've obviously built all of this out. What's next on your horizon? So I just shared a link in chat. If you're interested, this is the kind of... So, how do you roll this out at scale in an organization? I say it scale really is. I think you need a dedicated person or team ideally. And the reason why I say that is because like, things like these automation tools are great, but if you give it to every single person in the organization, you understand that with a lot of people reinventing the wheel 17, 30 times, right? So, someone or a small team of people, depending on the size of an organization, who's job at is to build these automations and go and find use cases and workflows. And I'm using terminology that's in that document that's quite specific to a concept of value stream thinking and flow engineering. But finding flows, process flows within organizations, you can just think of them as process flows. And which ones are going to have the biggest impact and then also uncovering where the bottleneck is. Because the reality is if you optimize anything else other than the bottleneck, no work flows through any faster. People will always come to you and go like, I really want to automate this, but actually it might be something that they hate, but it might not be the bottleneck. And then the problem is then is like, the meaningful gains to your point Roberto in terms of measurements in zero. You don't, you've just removed a tedious task, but that person's actually probably sat there tooling their thumbs now more and waiting for work, but actually it doesn't mean that value flows through your organization any faster. So yeah. So just to understand a little bit of the, what it looks like from a BDR or a perspective, if I played back, they got that Google sheet, the R name over the account in the Google sheet and then make.com feels the rest of the, we're making it even easier for the AEs actually. So there will be, they basically tick a box in Salesforce and then all that information link, all the links for the information will be put into Salesforce documents. So they won't even have to deal with the Google sheet. That was a temporary solution as we were kind of ramping up. But yeah, it wouldn't, so like you can have it, the ideal scenario is that you're not building additional tooling that the AEs actually interact with. Yeah. You're delivering this value where they work. So whether that's Salesforce or, you know, wherever, then the ideal scenario is you integrate it into all the tools that they already use. So that, that, that, that technical question and answer agent could have been put in anywhere, right? We could have created a whole new application and a chat prompt, but we didn't, we put it into Slack. Why? That's where the AEs already asked those questions. Same goes for AEs and like, you know, wanting to know more about, you know, if you get, if you're an A and you get given a new set of accounts, those new set of accounts are in Salesforce, it wouldn't have been nice just to go into those new set of accounts and already have all of that account research already there in links ready for you to click. And it's continually updated, you know, once a month, once every, you know, a couple of weeks or whatever, so that it's, it's liable. It's up to date. What, what are, I mean, apart from dedicated resources and so on, do you ever view of what are the running cost of this stuff? Like, so not a lot, really not a lot. So one of the other reasons why I think it's important to have a one person kind of who really understands best practice is model selection is quite key. Like, everyone can throw the biggest and best model at it, but those big models are expensive when you're talking about AI. So knowing which model to use for what task, like creating an email, it does not require a cloud four opus, right, doesn't even need reasoning mode on cloud four, sonnet, right, you can just turn off a reasoning mode, fire it at its on it and it's going to cost you 0.001 of a cent, right? Doing a deep account research, you want opus, you want deep research, you want web search, that's going to cost you a cent probably to do that. So you need to think about how that's going to be implemented. So it doesn't cost the company loads of money. When it comes to the workflow automation platforms, they all work in similar ways. Basically, really, just paying for the compute, makes cloud hosted. So you're paying for the number of minutes of execution time. It's going through. And it's self hosted. So that in an instance is just running on a VM, at one single VM with backups, and it just executes up. That is costing us like, I think, $20 or $20 a quarter. Well, that's super, super useful Simon. And look, as I said, we are at the beginning of this journey, right? We have some tools here and there. But the reality is that, I mean, you shared some information up for your company, sharing some from ours, which is also new to some of the people in this group. So we are changing CEO. So with a new incoming CEO, of course, there's a big interesting big in their market, changing, changing how we do business. The previous one has been CEO for the past 14 years. Right? There's there. We are in the process of change. One of the initiatives that we will run, really, the senior executive level is an exact dedicated to adoption of AI and these kind of initiatives. So we're coming at it as a strategic initiative company wide. Of course, for me, I lead the go to market for identity verification. For me, that needs to be the first place where we adopt the best practices. So really, really appreciate Simon the time that you did continue. Great, great, great stuff. Thanks, Joey, for inviting me, frankly. Yeah, I know. Good stuff to see what you built here. Yeah, I really appreciate it Simon. Yeah, really, really, really, really interesting to see what you're doing. If there's anything we can do to reciprocate, like, obviously we can't tell you about our naughty AI practices, but yeah, like if there's anything we can do, I guess. Sure, you say sports, but not sure. I tell you what, get lab doesn't use Salesforce in the best when it possible. I don't think anyone uses Salesforce in like a standard operating way. It seems to be like, it's the first SaaS product ever really that really took off and it's now the one that everyone loves to hate. So anyway, anyway, always is. But yeah, I mean, I appreciate it. But I mean, like we don't need anything back at the moment, I think, but I think, you know, I'm just a firm believer in, you know, get lab as, as you've said already, is, you know, a very transparent company. We like to share as much as we possibly can. Me and Joe got, you know, sort of acquainted because we're both S e S a leaders in a similar area. And it was a good opportunity for us to just to kind of build a bit of a friendship and a mutual pain points, perhaps understanding. But I mean, yeah, if we can do more things like this, then this is fantastic. But yeah, we're always willing to share. So yeah, I appreciate it. Thank you very much. I think that's it. And that's it. I'm just, I don't say much, but thank you. I really enjoyed that level this. I love that a lot of this exists in separate tools that usually costs a lot of money for sales teams to try and get approval to buy. And the other way you've just been able to kind of build it yourself and say, well, I'm not in it probably works better than. There's a lot of people out there who are providing kind of go to market AI tooling and the reality is that they all they're really doing is building just what I've just shown you now. And the reality is it won't be tailored as well. Yeah. Your own organization as well. And it all looks the same. Yeah. A lot of the AI stuff just all looks the same now. And it's really interesting. Yeah. Yeah. I'm not trying to sell make or anything. And by the way, if I have a referral, I wish I had one. But yeah. But yeah, what I would say is any ends very easy to get started with. So like, if you want to have a player around with any and you can literally go to their website. And there's like install locally kind of style stuff and you can spin it up. It does start getting a little bit more complex when it's comes to like all of it uses like a auth and integration with all of the different tools. If you're running it locally, you can't do that very easily because you need like call back your URLs and stuff. But if you just want to have a quick play with it and have a look at it, you can definitely do that. Most of them, one of the questions I asked at the beginning was like, do you have an AI console API access rather than just chat the co pilot. That is required for most of this, right? Like, because you're going to interact with the API run the front end chat box. And they're also build differently because they build per use. So again, actually, the running costs are zero to start with until you actually start using it, which actually is easier. And of course, the basic question, I guess in the enterprise version that you have off-clawed. Open AI or whatever, everything that you put there is isolated in your own instance. It's not, yeah. So we have agreements with anthropic and with open AI and with Google for Gemini, chat, and Claude such that any data that we put in there will never ever be used for training. And it's only retained for as long as we have it. So as soon as we delete it, effectively, it's gone. So yeah, yeah, we can do that. Yeah, no, it's better. So you should have an executive sponsor from the top down like we're kind of building now or something that came from bottom up to this. So this is something that, so as I said, I'm a champion within the go-to-market organization, but I actually spoke to, I've spoken to the CEO, the CRO and the CIO numerous times about these things. And they're all very interested in this. So yes, definitely exact sponsorship right from the top. Yeah. Yeah, it helps possibly. Cool. Yeah, thanks again, Simon. Really appreciate it's time. Yeah, I'm sure we'll obviously speak into you about this in our subsequent sessions, but really appreciate it. 100%. Thanks a lot, Simon. Have a great weekend. Thank you. Thank you.
